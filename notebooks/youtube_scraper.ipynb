{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping video data using YouTube API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up\n",
    "\n",
    "Run the following instructions on your terminal:\n",
    "``` bash\n",
    "pip install google-api-python-client\n",
    "pip install --upgrade google-api-python-client\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from IPython.display import JSON\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_file_path = \"../credentials.json\"\n",
    "\n",
    "# open the file and load the data into a variable\n",
    "with open(credentials_file_path, \"r\") as f:\n",
    "    credentials = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating service object of the youtube version 3 API\n",
    "youtube = build('youtube', 'v3', developerKey=credentials['youtube_api_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a list of music videos so that we have a list of videos to analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the request object\n",
    "\n",
    "\n",
    "def youtube_search(max_results:int, query:str, region:str, searchtype:str, category:int, orderfilter: str):\n",
    "    search_data = []\n",
    "    video_ids = []\n",
    "    \n",
    "    youtube_search_request = youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        maxResults= max_results,\n",
    "        q= query,\n",
    "        regionCode= region,\n",
    "        type=searchtype,\n",
    "        videoCategoryId=category,\n",
    "        order = orderfilter,\n",
    "        fields=\"items(id/videoId,snippet(channelId,channelTitle,description,title)),nextPageToken,pageInfo,prevPageToken,regionCode\"\n",
    "    )\n",
    "    \n",
    "    # Execute the request and get the response\n",
    "    youtube_search_response = youtube_search_request.execute()\n",
    "    \n",
    "    # iterate through each element in the nested dictionary to get the relevant values of each video\n",
    "    for item in youtube_search_response['items']:\n",
    "        video_id = item['id']['videoId']\n",
    "        title = item['snippet']['title']\n",
    "        channel_id = item['snippet']['channelId']\n",
    "        channel_title = item['snippet']['channelTitle']\n",
    "        description = item['snippet']['description']\n",
    "        \n",
    "        # append the relevant values to the dictionarys to save as a dataframe\n",
    "        search_data.append({\n",
    "        'video_id': video_id,\n",
    "        'title': title,\n",
    "        'channel_id': channel_id,\n",
    "        'channel_title': channel_title,\n",
    "        'description': description\n",
    "        })\n",
    "    \n",
    "        # the video_id dictionary will be used in the second part of the code involving the .videos() method\n",
    "        video_ids.append (video_id)\n",
    "        \n",
    "    return search_data, video_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_search_data, mv_video_id = youtube_search(100, \"official music video\", \"US\", \"video\", 10, \"viewCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json \n",
    "with open('../data/search_data.json', 'w') as json_file:\n",
    "    json.dump(youtube_search_data, json_file, indent=4)\n",
    "\n",
    "yt_search_df = pd.DataFrame(youtube_search_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the list of music videos, get statistics on each video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_stats(videoId:list):\n",
    "\n",
    "    video_data=[]\n",
    "    # create the request object\n",
    "    # from the above response, we already have the channelId, channelTitle, videoID, categoryID, \n",
    "    video_request = youtube.videos().list(\n",
    "    part = \"statistics, id, topicDetails\",\n",
    "    id = videoId\n",
    "    )\n",
    "    video_response = video_request.execute()\n",
    "\n",
    "    # iterate through each element in the nested dictionary to get the relevant values\n",
    "    for item in video_response['items']:\n",
    "        like_count = item['statistics']['likeCount']\n",
    "        view_count = item['statistics']['viewCount']\n",
    "        comment_count = item['statistics']['commentCount']\n",
    "        wikipedia_category = item['topicDetails']['topicCategories'] # this output gives us a few wikipedia links of genres that we will have to clean up to get the genre\n",
    "\n",
    "        # append the relevant values to the data dictionary to save as a dataframe\n",
    "        video_data.append ({\n",
    "        'video_id': item['id'],\n",
    "        'like_count': like_count,\n",
    "        'view_count': view_count,\n",
    "        'comment_count': comment_count,\n",
    "        'wikipedia_category': wikipedia_category\n",
    "        })\n",
    "        \n",
    "    return video_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_video_stats = get_stats(mv_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json \n",
    "with open('../data/mv_stats_data.json', 'w') as json_file:\n",
    "    json.dump(mv_video_stats, json_file, indent=4)\n",
    "\n",
    "mv_videostats_df = pd.DataFrame(mv_video_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the mv stats and search dataframes\n",
    "searchandstats_merged_df = pd.merge(yt_search_df, mv_videostats_df, left_on='video_id', right_on='video_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
