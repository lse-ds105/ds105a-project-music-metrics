{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **04 Data Expansion**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding our dataframe through various methods to get a richer data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set-up ⚙️**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import spotipy\n",
    "from base64 import *\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from datetime import datetime\n",
    "import os\n",
    "os.chdir(os.path.expanduser(\"../\"))                 # change directory to main project directory\n",
    "\n",
    "from functions.data_expansion_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we are in the correct current working directory\n",
    "\n",
    "*⚠️ Note: We should be in the main project directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will proceed with expansion of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/raw_compiled_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply our function to find the \"genre level\" of a song.\n",
    "\n",
    "We noticed a significant lack of categories of a song based on Wikipedia search. Moreover, every song has a default category of \"music\", which is irrelevant. Hence, instead of working with small datapoints by having multiple categories of genres, we broadly categorised the songs into \"Low\", \"Medium\" or \"High\". This determines a rough level of \"diversity\" of a song by looking at how many, instead of which, genres the songs are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'wikipedia_categories': 'genre_level'})\n",
    "df['genre_level'] = df['genre_level'].apply(lambda x: get_category_number(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply our sentiment analysis functions to evaluate lyrics quantitatively. We want the scores \"positive\", \"neutral\", \"negative\" and \"compound\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we first want to ensure that our lyrics are in `str` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics'] = df['lyrics'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(lyric):\n",
    "    lyric_string = str(lyric)\n",
    "    scores = sid.polarity_scores(lyric_string)\n",
    "    list = [scores['neg'], scores['neu'], scores['pos'], scores['compound']]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_positive'] = df['lyrics'].apply(lambda x: get_sentiment_score(x)[2])\n",
    "df['sentiment_neutral'] = df['lyrics'].apply(lambda x: get_sentiment_score(x)[1])\n",
    "df['sentiment_negative'] = df['lyrics'].apply(lambda x: get_sentiment_score(x)[0])\n",
    "df['sentiment_compound'] = df['lyrics'].apply(lambda x: get_sentiment_score(x)[3])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to conduct a sentiment analysis on the comments as well. However, we noticed that comments are mostly irrelevant to the song, and we are unsure of the reliability of such data. However, we still want to see if there are any insights. Hence, we only want to find out the \"sentiment compound\" of the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2  = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['comments'] = df2['comments'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={'comments': 'comments_sentiment'})\n",
    "df2['comments_sentiment'] = df2['comments_sentiment'].apply(lambda x: get_sentiment_score(x)[3])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply our function to find the lexical richness of a song.\n",
    "\n",
    "We define lexical richness as the proportion of unique words as total words in a song, giving us a proxy measure of the range of vocabulary that artists use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['lexical_richness'] = df2['lyrics'].apply(lambda x: get_lexical_richness(x))\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find song length as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['song_length'] = df2['lyrics'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that \"sentiment compound\" measures how positive or negative a song is, and the value tend to be closer to the extreme (close to +-1). Here we indicate another variable \"sentiment compound absolute\", where we ignore whether the song is happy or sad, and measure how \"extreme\" the lyrics are by considering the absolute value of \"sentiment compound\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sentiment_compound_absolute'] = df2['sentiment_compound'].abs()\n",
    "\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open JSON file containing credentials\n",
    "\n",
    "*⚠️ Note: Our credentials should be stored in a file titled `credentials.json` and stored in the root of the project folder*\n",
    "\n",
    "*⚠️ Caution: Run the notebook 03 Spotify Token Generator first. The following codes will not run unless the token has been added into the credentials folder, saved as `token`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_file_path = './credentials.json'\n",
    "\n",
    "with open(credentials_file_path, 'r') as f:\n",
    "    credentials = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now integrate the 'spotipy' package and the search() function.\n",
    "\n",
    "From there, we are able to get data in the json file such as release date, a popularity score, whether the song is explicit, and the number of markets that the song is in during its initial release. We navigate through the json file to find the data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.Spotify(auth=credentials['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create the functions to get the data. \n",
    "\n",
    "We were not able to store these functions separately in our functions folder as they require the token to work. Hence it will be easier to run them within this notebook instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_release_date(song):\n",
    "    result = sp.search(song)\n",
    "    tracks = result['tracks']['items']\n",
    "    if len(tracks) > 0:\n",
    "        return tracks[0]['album']['release_date']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_popularity(song):\n",
    "    result = sp.search(song)\n",
    "    tracks = result['tracks']['items']\n",
    "    if len(tracks) > 0:\n",
    "        return tracks[0]['popularity']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_explicitness(song):\n",
    "    result = sp.search(song)\n",
    "    tracks = result['tracks']['items']\n",
    "    if len(tracks) > 0:\n",
    "        return tracks[0]['explicit']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_market_number(song):\n",
    "    result = sp.search(song)\n",
    "    tracks = result['tracks']['items']\n",
    "    if len(tracks) > 0:\n",
    "        return len(tracks[0]['available_markets'])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the codes one by one due to the large volumes of data. Note that strength of internet connection may significantly affect the run time. We have break this down into multiple dataframes instead there is a need to go back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['release_date'] = df3['title'].apply(lambda x: get_release_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['popularity'] = df4['title'].apply(lambda x: get_popularity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['explicitness'] = df5['title'].apply(lambda x: get_explicitness(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['markets'] = df6['title'].apply(lambda x: get_market_number(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having `Nan` values could affect our code later on, hence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df7.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We categorise the market availability into \"Low\", \"Medium\" and \"High\".\n",
    "\n",
    "We have noticed that during an initial release of a song, the song is either in (1) all 184 markets, (2) slightly less than 184 markets, or (3) have very restricted markets (<50). Hence it is reasonable for us to categorise the songs as such, where high category indicates less censorship/songs are more global in nature instead of local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['markets'] = df7['markets'].apply(lambda x: market_availability_category(x))\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to convert our date to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['release_date'] = df7['release_date'].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, saving our final data into csv, and we are ready for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('./data/final_compiled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
