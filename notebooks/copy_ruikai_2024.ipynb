{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Set-up:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the additional packages to be installed on the terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install scikit-learn\n",
    "pip install rpy2\n",
    "pip install spotipy\n",
    "pip install nltk\n",
    "pip install wordcloud\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code to install the packages required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from plotnine import *\n",
    "import plotnine as p9\n",
    "import re\n",
    "from scrapy import Selector\n",
    "import requests as requests\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import spotipy\n",
    "import base64\n",
    "from requests import post\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from datetime import datetime\n",
    "from sklearn import *\n",
    "from base64 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Dataframe from merged YouTube Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('../data/merged_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract artist and song from 'title'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_artist_and_song(string):\n",
    "\n",
    "    pattern_in_brackets = re.compile(r'\\[.*?\\]')\n",
    "    pattern_in_parentheses = re.compile(r'\\(.*?\\)')\n",
    "\n",
    "    string = re.sub(pattern_in_brackets, '', string)\n",
    "    string = re.sub(pattern_in_parentheses, '', string)\n",
    "\n",
    "    if '-' in string:\n",
    "        artist, song = string.split('-', 1)\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "    return [artist.strip(), song.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge = merged_df\n",
    "\n",
    "new_merge['Artist'] = new_merge['title'].apply(lambda x: extract_artist_and_song(x)[0])\n",
    "new_merge['Song'] = new_merge['title'].apply(lambda x: extract_artist_and_song(x)[1])\n",
    "\n",
    "new_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funtion to generate the song URL _(this will be used for web scraping later on)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song_url(song_artist, song_title):\n",
    "    '''\n",
    "    Returns a string of the URL for the Genius page of the song\n",
    "\n",
    "        Parameters:\n",
    "            song_artist (str): The artist of the song\n",
    "            song_title (str): The title of the song\n",
    "\n",
    "        Returns:\n",
    "            song_url (str): The URL for the Genius page of the song\n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://genius.com/'\n",
    "    \n",
    "    # format the artist name and song title\n",
    "    song_artist = song_artist.replace('&', 'and')\n",
    "    formatted_artist = song_artist.lower().replace(' ', '-')\n",
    "    formatted_title = song_title.lower().replace(' ', '-')\n",
    "    \n",
    "    # generate the song URL by concatenating strings according to Genius formatting\n",
    "    song_url = f'{base_url}{formatted_artist}-{formatted_title}-lyrics'\n",
    "\n",
    "    return song_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge['Genius_URL'] = new_merge.apply(lambda row: generate_song_url(row['Artist'], row['Song']), axis=1)\n",
    "\n",
    "new_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to scrape the lyrics based on the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_lyrics(session, song_url):\n",
    "    '''\n",
    "    Returns a string of song lyrics, with each line separated by a new line\n",
    "\n",
    "        Parameters:\n",
    "            session (variable): The session that has been initialised for requesting from the Genius website\n",
    "            song_url (str): The URL of the Genius page for the song\n",
    "\n",
    "        Returns:\n",
    "            lyrics (str): The lyrics of the song\n",
    "    '''\n",
    "    \n",
    "    # use initialised session to enhance performance\n",
    "    response = session.get(song_url, timeout=10)\n",
    "    sel = Selector(text=response.text)\n",
    "\n",
    "    if response.status_code != 200: return None\n",
    "    \n",
    "    print(response.status_code)\n",
    "    \n",
    "    # scrape lyrics into one large string\n",
    "    raw_lyrics = ' '.join(sel.css('div.Lyrics__Container-sc-1ynbvzw-1.kUgSbL ::text').getall())\n",
    "\n",
    "    # clean lyrics using regular expression to remove words in square brackets\n",
    "    pattern = r'\\[.*?\\]'\n",
    "    result_string = re.sub(pattern, '', raw_lyrics)\n",
    "    lyrics = ' '.join(result_string.split())\n",
    "\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_file_path = \"../credentials.json\"\n",
    "\n",
    "with open(credentials_file_path, \"r\") as f:\n",
    "    credentials = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_session = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under 'wikipedia_categories', there are separate links for different potential genres\n",
    "\n",
    "We have noticed that:\n",
    "* Each link is separated by a comma ','\n",
    "* Every song has at least one category â€“ 'music'\n",
    "* Some songs are in multiple categories, majority of them only has only one, some has two, songs with two and more categories are extremely rare\n",
    "\n",
    "Therefore, we can count the number of commas to determine the number of categories, with the function as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_number(x):\n",
    "    string = str(x)\n",
    "    return string.count(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge['category_number'] = new_merge['wikipedia_categories'].apply(lambda x: get_category_number(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge2 = new_merge.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_merge = new_merge.head(200)\n",
    "big_merge['lyrics'] = big_merge.apply(lambda row: scrape_lyrics(my_session, row['Genius_URL']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge2['lyrics'] = new_merge2.apply(lambda row: scrape_lyrics(my_session, row['Genius_URL']), axis=1)\n",
    "\n",
    "new_merge2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Analyse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We create a new dataframe with the necessary headers only, removing 'None' values or duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge3 = new_merge2.dropna()\n",
    "\n",
    "df = new_merge3[['Artist', 'Song', 'like_count', 'view_count', 'comment_count', 'lyrics', 'category_number']].dropna().drop_duplicates(subset = ['Song'])\n",
    "\n",
    "df = df[df['lyrics'] != '']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported package to analyse sentiments\n",
    "\n",
    "We create function and apply it to dataframe|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(lyric):\n",
    "    scores = sid.polarity_scores(lyric)\n",
    "    list = [scores['neg'], scores['neu'], scores['pos'], scores['compound']]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_positive'] = df['lyrics'].apply(lambda x: get_sentiment_score(x)[2])\n",
    "df['sentiment_neutral'] = df['lyrics'].apply(lambda x: get_sentiment_score(x)[1])\n",
    "df['sentiment_negative'] = df['lyrics'].apply(lambda x: get_sentiment_score(x)[0])\n",
    "df['sentiment_compound'] = df['lyrics'].apply(lambda x: get_sentiment_score(x)[3])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define lexical richness as the proportion of unique words to total words used, a quantitative way to analyse the richness of vocabulary used in a song. Using function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lexical_richness(lyric):\n",
    "    total_words = len(lyric.split())\n",
    "    unique_words = len(set(lyric.split()))\n",
    "    lexical_richness = unique_words/total_words*100\n",
    "    return round(lexical_richness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lexical_richness'] = df['lyrics'].apply(lambda x: get_lexical_richness(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find song length as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['song_length'] = df['lyrics'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_compound_absolute'] = df['sentiment_compound'].abs()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Spotify API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we integrate spotify API as well to find even more categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = credentials['client_id']\n",
    "client_secret = credentials['client_secret']\n",
    "\n",
    "client_creds = f\"{client_id}:{client_secret}\"\n",
    "base64_client_creds = b64encode(client_creds.encode()).decode()\n",
    "\n",
    "auth_url = 'https://accounts.spotify.com/api/token'\n",
    "headers = {\n",
    "    'Authorization': f'Basic {base64_client_creds}'\n",
    "}\n",
    "payload = {\n",
    "    'grant_type': 'client_credentials'\n",
    "}\n",
    "\n",
    "response = requests.post(auth_url, headers=headers, data=payload)\n",
    "\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 'spotipy' package and the search() function, we are able to get data in the json file such as release date, a popularity score, whether the song is explicit, and the number of markets that the song is in during its initial release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_release_date(song):\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    result = sp.search(song)\n",
    "    release_date = result['tracks']['items'][0]['album']['release_date']\n",
    "    return release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popularity(song):\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    result = sp.search(song)\n",
    "    popularity = result['tracks']['items'][0]['popularity']\n",
    "    return popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explicitness(song):\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    result = sp.search(song)\n",
    "    explicitness = result['tracks']['items'][0]['explicit']\n",
    "    return explicitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_number(song):\n",
    "    client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    result = sp.search(song)\n",
    "    available_markets = result['tracks']['items'][0]['available_markets']\n",
    "    return len(available_markets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating these into our existing dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release_date'] = df['Song'].apply(lambda x: get_release_date(x))\n",
    "df['popularity'] = df['Song'].apply(lambda x: get_popularity(x))\n",
    "df['explicitness'] = df['Song'].apply(lambda x: get_explicitness(x))\n",
    "df['markets'] = df['Song'].apply(lambda x: get_market_number(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to convert our date to datetime format for ease of plotting later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(x):\n",
    "    try:\n",
    "        pd.to_datetime(x)\n",
    "        return pd.to_datetime(x)\n",
    "    except:\n",
    "        None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release_date'] = df['release_date'].apply(lambda x: convert_date(x)).dropna()\n",
    "# df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the number of markets of song release, we found some interesting facts:\n",
    "\n",
    "For an initial release of song, it is in either:\n",
    "* all 184 markets in the world\n",
    "* slightly less than 184 markets (a sign that there are some censorship in some countries, a hint that the song may be culturally inappropriate/politically sensitive)\n",
    "* or very little markets (<50) (a sign that the song is deliberately only released in some markets, targeting niche categories)\n",
    "\n",
    "Hence justifying the below function, categorising them into high, medium, or low level of outreach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_availability_category(x):\n",
    "    number = int(x)\n",
    "    if number == 184:\n",
    "        return 'High'\n",
    "    elif 50 < number < 184:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['markets'] = df['markets'].apply(lambda x: market_availability_category(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly, for song categories:\n",
    "\n",
    "We initially attempted to obtain song genres via YouTube, Genius or Spotify. However, we faced significant difficulties due to the fact that:\n",
    "* The data is not explicitly available â€“ these platforms offer limited sources of data to public due to privacy reasons\n",
    "* It is very difficult to get the genre via the API itself\n",
    "\n",
    "Therefore, we enlisted Wikipedia, an open source, to find out on the song genre/category. However, due to the limited amount of categorisations there are on Wikipedia, we focus on the number of categories, i.e. number of wikipedia pages they occur instead.\n",
    "* Most songs do not belong to any specific category on Wikipedia, they are being categorised as \"music\".\n",
    "* For most of the other songs, they belong to two Wikipedia categories, \"music\" and something else, such as \"electro\"\n",
    "* The rest of the songs are extreme minorities which belongs to three or more Wikipedia categories\n",
    "\n",
    "Hence justifying our rationale to have broad categories. Songs that are not relevant enough to have more than one genre are categorised as \"Low\" in terms of category popularity; two as \"Medium\", three or more as \"High\". The function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_popularity(x):\n",
    "    number = int(x)\n",
    "    if number == 1:\n",
    "        return 'Low'\n",
    "    elif number == 2:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_number'] = df['category_number'].apply(lambda x: category_popularity(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(df.iloc[0,5])\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df[['like_count','view_count','comment_count', 'sentiment_positive', 'sentiment_neutral', 'sentiment_negative', 'sentiment_compound_absolute', 'lexical_richness', 'song_length', 'popularity']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df2 = corr_df. \\\n",
    "        melt(ignore_index=False) \\\n",
    "        .reset_index()\n",
    "\n",
    "corr_df2['rounded_value'] = corr_df2['value'].apply(lambda x: np.round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = p9.ggplot(\n",
    "        mapping = p9.aes('index', 'variable', fill = 'value'),\n",
    "        data = corr_df2\n",
    "    ) + \\\n",
    "        p9.geom_tile() + \\\n",
    "        p9.geom_label(\n",
    "            p9.aes(label = 'rounded_value'),\n",
    "            fill = 'white',\n",
    "            size = 8\n",
    "        ) + \\\n",
    "        p9.scale_fill_distiller() + \\\n",
    "        p9.theme_minimal() + \\\n",
    "        p9.labs(\n",
    "            title = 'Correlation Matrix',\n",
    "            x = '',\n",
    "            y = ''\n",
    "        ) + \\\n",
    "        p9.theme(\n",
    "            axis_text_x = element_text(angle = 90)\n",
    "        )\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = p9.ggplot(\n",
    "    mapping = p9.aes(x = 'sentiment_compound'),\n",
    "    data = df\n",
    ") + \\\n",
    "geom_histogram(binwidth=0.05)\n",
    "\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = (\n",
    "    ggplot(df) +\n",
    "    aes(x = 'explicitness', y = 'popularity') +\n",
    "    geom_boxplot()\n",
    ")\n",
    "\n",
    "boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = (\n",
    "    ggplot(df) +\n",
    "    aes(x = 'release_date', y = 'song_length', colour = 'explicitness') +\n",
    "    geom_point(alpha = 0.5) +\n",
    "    geom_smooth(method = \"lm\") +\n",
    "    scale_x_datetime(\n",
    "        limits=(datetime(2000, 1, 1), datetime(2024, 1, 1)),\n",
    "    )\n",
    ")\n",
    "\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour = (\n",
    "    ggplot(df) +\n",
    "    aes(x = 'popularity', y = 'song_length') +\n",
    "    geom_bin2d() +\n",
    "    theme_classic()\n",
    ")\n",
    "\n",
    "contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"../data/json_for_plot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour = (\n",
    "    ggplot(df) +\n",
    "    aes(x = 'lexical_richness', y = 'sentiment_compound', z = 'popularity') +\n",
    "    geom_contour_filled(aes(fill = 'level') +\n",
    "    geom_contour(colour = 'black'))\n",
    ")\n",
    "\n",
    "contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = (\n",
    "    ggplot(df) +\n",
    "    aes(x = 'popularity', colour = 'category_number', fill = 'category_number') +\n",
    "    geom_density(alpha = 0.2)\n",
    ")\n",
    "\n",
    "distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "install.packages(\"IRkernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "install.packages(\"IRkernel\")\n",
    "plot = (\n",
    "    ggplot(df, aes(x='lexical_richness', y='sentiment_compound', z='popularity')) +\n",
    "    geom_contour_filled(aes(fill='..level..')) +\n",
    "    geom_contour(color='black') +\n",
    "    scale_fill_cmap(name='viridis')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
